# -*- coding: utf-8 -*-
"""ipills.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BIBMpB8ZNCTdBmfH9fNJxinj5PXHZrGI
"""

import RPi.GPIO as GPIO
import time
import os
import playsound as ps
import numpy as np
import matplotlib.pyplot as plt
import glob
import button


in1 = 18    
in2 = 15
in3 = 16
led1 = 11
led2 = 12

def button():
    # Pin Setup:
    # Board pin-numbering scheme
    GPIO.setmode(GPIO.BOARD) #보이는 데로 꽂은 모드
    # set pin as an output pin with optional initial state of HIGH
    GPIO.setup(in1, GPIO.IN)
    GPIO.setup(in2, GPIO.IN)
    GPIO.setup(in3, GPIO.IN)


    prev_value = None

    print("Starting demo now! Press CTRL+C to exit")
    curr_value = GPIO.LOW
#안내멘트
    ps.playsound('guide.wav')
    try:
        while True:
#버튼 선택 while 
            value1 = GPIO.input(in1)
            value2 = GPIO.input(in2)
            value3 = GPIO.input(in3)
            if value1 == 1:
              return 1
            elif value2 == 1:
              return 2
            elif value3 == 1:
              return
                
    finally:
        GPIO.cleanup()

def save_img():
  #setup
  GPIO.setup(led1, GPIO.OUT)
  GPIO.setup(led2, GPIO.OUT)
  cam1 = cv2.VideoCapture(0)
  cam2 = cv2.VideoCapture(1)

  #1번 cam&조명 
  #...
  GPIO.ouput(led1, GPIO.HIGH)
  ret, frame = cam1.read()
  cv2.imwrite('data/image/img1', frame)
  GPIO.ouput(led1, GPIO.LOW)
  #2번
  GPIO.ouput(led2, GPIO.HIGH) 
  ret, frame = cam2.read()
  cv2.imwrite('data/image/img2', frame)
  GPIO.ouput(led2, GPIO.LOW)


if __name__ == '__main__':
    main()

# 글자 단위로 읽은 결과들 리스트화

def gathering_symbols(loc):
  client = vision.ImageAnnotatorClient()
  result = []
  for path in loc:
    with io.open(path, 'rb') as image_file:
        content = image_file.read()
        
    image = vision.Image(content=content)
    response = client.text_detection(image=image)

    try:
      symbols = response.full_text_annotation.pages[0].blocks[0].paragraphs[0].words[0].symbols
      for symbol in symbols:
        result.append(symbol.text)
    except: IndexError

    if response.error.message:
        raise Exception(
            '{}\nFor more info on error messages, check: '
            'https://cloud.google.com/apis/design/errors'.format(
                response.error.message))
        
  return result

pills_arr = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]


while True:
  button_situation= button()
  if button_situation>0:
    save_img()
    # yolov5
    os.system('python yolov5/detect.py —save-txt —save-conf —weights yolov5/nv5_300_best.pt —data yolov5/data.yaml —img 320 —conf 0.5 —source yolov5/data/images ')
    

    # 랭크 텍스트 경로
    text_file_list = glob('yolov5/runs/*.s') 

    # txt 파일 to ocr 
    with open(text_file_list[0], 'r') as f:
     data = f.readlines()[1:5]
    pills_rank = []
    for i in data:
        pills_rank.append(int(i.split()[0]))

    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = "./my_google_api_key.json"
    loc=glob.glob('./yolov5/run/detect/exp*.jpg')    # front, back image reading
    chars = gathering_symbols(loc)    # OCR이 이미지 앞,뒷면에서 글자 단위로 문자를 읽어 chars 리스트에 저장
    
    DICT = {}

    for i in pills_rank:    # YOLO가 낸 후보들 가운데 정답 글자를 맞춘 비율(점수)을 계산하여 후보:점수 dictionary 만듦
      count = 0
      for char in chars:
        if char in list(data['표시'][i]):
          count+=1
      score = count/len(list(data['표시'][i]))
      DICT[i] = score
    
    answer = max(DICT, key=DICT.get)    # 만약 OCR 점수가 모두 같을 경우, 자동으로 pills_rank 1위가 answer로 채택됨


#TTS

    predic_name='azp'
    # 이름과 사용법? 출력
    ps.playsound('pills/'+predic_name+'name.wav')
    ps.playsound('pills/guide.wav')

    
    but= button()
    
    #효과 효능
    if but==1:
      ps.playsound('pills/'+predic_name+'efficacy.wav')
    #복용량
    elif but==2:
      ps.playsound('pills/'+predic_name+'dosage.wav')
    #주의사항
    elif but==3:
      ps.playsound('pills/'+predic_name+'caution.wav')

